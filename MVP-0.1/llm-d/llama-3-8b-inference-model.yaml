apiVersion: inference.networking.x-k8s.io/v1alpha2
kind: InferenceModel
metadata:
  name: llama-3-8b
  namespace: llm-d
spec:
  modelName: llama-3-8b          # This is the "model" name for API calls
  poolRef:
    name: default-pool           # Must match the pool you created
  criticality: Standard          # Can be: Critical, Standard, Sheddable
  targetModels:
    - name: llama-3-8b           # Can match modelName if only one version
